{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MIWdWJ8v_Em"
   },
   "source": [
    "# NLP 실습 #3: N-gram Language model\n",
    "황순원의 '소나기' 로 n-gram language model 학습하고 사용해보기\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "* 준비 : konlpy와 kenlm library 설치\n",
    "\n",
    "* Step 1: Data preprocessing - tokenization\n",
    "\n",
    "* Step 2: Language Model 생성\n",
    "\n",
    "* Step 3: Binary file로 Model 변환\n",
    "\n",
    "* Step 4: Model을 활용하여 시퀀스 scoring\n",
    "\n",
    "* Step 5: 주어진 시퀀스에서 다음 형태소 예측\n",
    "\n",
    "* Step 6: 주어진 시퀀스로 시작하는 문장을 예측\n",
    "\n",
    "* Step 7: 다른 말뭉치로 학습한 모델과 비교\n",
    "\n",
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u58Vf5yByd-j"
   },
   "source": [
    "## 준비: konlpy와 kenlm library 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sMydXeJivy7",
    "outputId": "b41fb390-9262-433d-f249-fc57a5565d72"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이', '문장', '이', '형태소', '단위', '로', '잘', '출력', '되', '나요', '?']"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. konlpy의 Kkma 형태소 분석기 import, 형태소 분석 예제\n",
    "\n",
    "from konlpy.tag import Kkma\n",
    "\n",
    "tokenizer = Kkma()\n",
    "tokenizer.morphs(\"이 문장이 형태소 단위로 잘 출력되나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxOsfjyKLaJ2",
    "outputId": "99112d08-8475-49f3-f5c6-197f9c9c1bab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이전에 nltk 및 'punkt' 모듈을 다운로드 하지 않은 경우에 주석을 풀고 run\n",
    "\n",
    "import nltk \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LcMwd5ZlLj22",
    "outputId": "9c0bdbb5-0b88-42ed-afbf-4dfa8755ef6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-04 09:30:19--  https://kheafield.com/code/kenlm.tar.gz\n",
      "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
      "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 491090 (480K) [application/x-gzip]\n",
      "Saving to: ‘STDOUT’\n",
      "\n",
      "-                   100%[===================>] 479.58K  1.43MB/s    in 0.3s    \n",
      "\n",
      "2021-01-04 09:30:19 (1.43 MB/s) - written to stdout [491090/491090]\n",
      "\n",
      "mkdir: cannot create directory ‘./kenlm/build’: File exists\n",
      "/content/kenlm/build\n",
      "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
      "-- Boost version: 1.65.1\n",
      "-- Found the following Boost libraries:\n",
      "--   program_options\n",
      "--   system\n",
      "--   thread\n",
      "--   unit_test_framework\n",
      "--   chrono\n",
      "--   date_time\n",
      "--   atomic\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /content/kenlm/build\n",
      "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
      "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
      "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
      "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
      "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
      "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
      "[ 38%] Built target kenlm_util\n",
      "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
      "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
      "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
      "[ 50%] Built target probing_hash_table_benchmark\n",
      "[ 51%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
      "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
      "[ 57%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
      "[ 57%] Built target kenlm_filter\n",
      "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
      "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
      "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
      "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
      "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
      "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
      "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
      "[ 71%] Built target kenlm\n",
      "[ 72%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
      "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
      "[ 76%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
      "[ 76%] Built target fragment\n",
      "[ 77%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
      "[ 77%] Built target build_binary\n",
      "[ 78%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
      "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
      "[ 80%] Built target query\n",
      "[ 81%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
      "[ 82%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
      "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
      "[ 86%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
      "[ 87%] Built target kenlm_benchmark\n",
      "[ 88%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
      "[ 90%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
      "[ 90%] Built target phrase_table_vocab\n",
      "[ 91%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
      "[ 93%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
      "[ 93%] Built target kenlm_builder\n",
      "[ 95%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
      "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
      "[ 96%] Built target filter\n",
      "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
      "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
      "[ 98%] Built target count_ngrams\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
      "[100%] Built target lmplz\n",
      "Collecting https://github.com/kpu/kenlm/archive/master.zip\n",
      "  Using cached https://github.com/kpu/kenlm/archive/master.zip\n",
      "Requirement already satisfied (use --upgrade to upgrade): kenlm==0.0.0 from https://github.com/kpu/kenlm/archive/master.zip in /usr/local/lib/python3.6/dist-packages\n",
      "Building wheels for collected packages: kenlm\n",
      "  Building wheel for kenlm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kenlm: filename=kenlm-0.0.0-cp36-cp36m-linux_x86_64.whl size=2333089 sha256=223ed19afe40f026d5a24a1ee02ed4e356e6f6af339c62b8e1298c785c2f9890\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-cioq88ex/wheels/2d/32/73/e3093c9d11dc8abf79c156a4db1a1c5631428059d4f9ff2cba\n",
      "Successfully built kenlm\n",
      "/content\n"
     ]
    }
   ],
   "source": [
    "# 3. kenlm 설치\n",
    "\n",
    "!wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz\n",
    "!mkdir -p ./kenlm/build\n",
    "%cd ./kenlm/build\n",
    "!cmake ..\n",
    "!make -j 4\n",
    "!pip install https://github.com/kpu/kenlm/archive/master.zip\n",
    "%cd /home/ch2_ngram_language_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THyoh5vyyvTE"
   },
   "source": [
    "## Step 1: Data preprocessing - tokenization\n",
    "&emsp;&emsp; sonagi.doc의 내용을 문장 단위로 분리.\n",
    "\n",
    "</br> &emsp;&emsp; <<Exercise 1>> 각 문장을 kkma 분석기로 형태소 단위로 분리.\n",
    "\n",
    "</br> &emsp;&emsp; 형태소로 분석된 문장들과 vocab들을 sonagi.txt, sonagi.voc 파일로 작성.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "gkaozFjwLqAF"
   },
   "outputs": [],
   "source": [
    "# 4. nltk import하고 sonagi.doc을 읽어들임. nltk의 sent_tokenize를 이용하여 sonagi.doc의 내용을 문장 단위로 분리\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "lines = []\n",
    "with open('sonagi.doc', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        lines.append(line)\n",
    "\n",
    "sentences = []\n",
    "for line in lines:\n",
    "    sentences.extend(sent_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6MrcQOMNTM-",
    "outputId": "7bb9f3b9-ef4e-43a9-b1c8-dbef99c4b1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수 있었다.', '소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다.', '서울서는 이런 개울물을 보지 못하기나 한 듯이.', '벌써 며칠째 소녀는, 학교에서 돌아오는 길에 물장난이었다.', '그런데, 어제까지 개울 기슭에서 하더니, 오늘은 징검다리 한가운데 앉아서 하고 있다.', '소년은 개울둑에 앉아 버렸다.', '소녀가 비키기를 기다리자는 것이다.', '요행 지나가는 사람이 있어, 소녀가 길을 비켜 주었다.', '다음 날은 좀 늦게 개울가로 나왔다.', '이 날은 소녀가 징검다리 한가운데 앉아 세수를 하고 있었다.', '분홍 스웨터 소매를 걷어올린 목덜미가 마냥 희었다.', '한참 세수를 하고 나더니, 이번에는 물 속을 빤히 들여다 본다.', '얼굴이라도 비추어 보는 것이리라.', '갑자기 물을 움켜 낸다.', '고기 새끼라도 지나가는 듯.', '소녀는 소년이 개울둑에 앉아 있는 걸 아는지 모르는지 그냥 날쌔게 물만 움켜 낸다.', '그러나, 번번이 허탕이다.', '그대로 재미있는 양, 자꾸 물만 움킨다.', '어제처럼 개울을 건너는 사람이 있어야 길을 비킬 모양이다.', '그러다가 소녀가 물 속에서 무엇을 하나 집어 낸다.', '하얀 조약돌이었다.', '그리고는 벌떡 일어나 팔짝팔짝 징검다리를 뛰어 건너간다.', '다 건너가더니만 홱 이리로 돌아서며,', '\"이 바보.\"', '조약돌이 날아왔다.', '소년은 저도 모르게 벌떡 일어섰다.', '단발 머리를 나풀거리며 소녀가 막 달린다.', '갈밭 사잇길로 들어섰다.', '뒤에는 청량한 가을 햇살 아래 빛나는 갈꽃뿐.', '이제 저쯤 갈밭머리로 소녀가 나타나리라.', '꽤 오랜 시간이 지났다고 생각됐다.', '그런데도 소녀는 나타나지 않는다.', '발돋움을 했다.', '그러고도 상당한 시간이 지났다고 생각됐다.', '저 쪽 갈밭머리에 갈꽃이 한 옴큼 움직였다.', '소녀가 갈꽃을 안고 있었다.', '그리고, 이제는 천천한 걸음이었다.', '유난히 맑은 가을 햇살이 소녀의 갈꽃머리에서 반짝거렸다.', '소녀 아닌 갈꽃이 들길을 걸어가는 것만 같았다.', '소년은 이 갈꽃이 아주 뵈지 않게 되기까지 그대로 서 있었다.', '문득, 소녀가 던지 조약돌을 내려다보았다.', '물기가 걷혀 있었다.', '소년은 조약돌을 집어 주머니에 넣었다.', '다음 날부터 좀더 늦게 개울가로 나왔다.', '소녀의 그림자가 뵈지 않았다.', '다행이었다.', '그러나, 이상한 일이었다.', '소녀의 그림자가 뵈지 않는 날이 계속될수록 소년의 가슴 한 구석에는 어딘가 허전함이 자리 잡는 것이었다.', '주머니 속 조약돌을 주무르는 버릇이 생겼다.', '그러한 어떤 날, 소년은 전에 소녀가 앉아 물장난을 하던 징검다리 한가운데에 앉아 보았다.', '물 속에 손을 잠갔다.', '세수를 하였다.', '물 속을 들여다보았다.', '검게 탄 얼굴이 그대로 비치었다.', '싫었다.', '소년은 두 손으로 물 속의 얼굴을 움키었다.', '몇 번이고 움키었다.', '그러다가 깜짝 놀라 일어나고 말았다.', '소녀가 이리로 건너오고 있지 않느냐.', \"'숨어서 내가 하는 일을 엿보고 있었구나.'\", '소년은 달리기를 시작했다.', '디딤돌을 헛디뎠다.', '한 발이 물 속에 빠졌다.', '더 달렸다.', '몸을 가릴 데가 있어 줬으면 좋겠다.', '이 쪽 길에는 갈밭도 없다.', '메밀밭이다.', '전에 없이 메밀꽃 냄새가 짜릿하게 코를 찌른다고 생각됐다.', '미간이 아찔했다.', '찝찔한 액체가 입술에 흘러들었다.', '코피였다.', '소년은 한 손으로 코피를 훔쳐내면서 그냥 달렸다.', \"어디선가 '바보, 바보' 하는 소리가 자꾸만 뒤따라오는 것 같았다.\", '토요일이었다.', '개울가에 이르니, 며칠째 보이지 않던 소녀가 건너편 가에 앉아 물장난을 하고 있었다.', '모르는 체 징검다리를 건너기 시작했다.', '얼마 전에 소녀 앞에서 한 번 실수를 했을 뿐, 여태 큰길 가듯이 건너던 징검다리를 오늘은 조심스럽게 건넌다.', '\"얘.\"', '못 들은 체했다.', '둑 위로 올라섰다.', '\"얘, 이게 무슨 조개지?\"', '자기도 모르게 돌아섰다.', '소녀의 맑고 검은 눈과 마주쳤다.', '얼른 소녀의 손바닥으로 눈을 떨구었다.', '\"비단조개.\"', '\"이름도 참 곱다.\"', '갈림길에 왔다.', '여기서 소녀는 아래편으로 한 삼 마장쯤, 소년은 우대로 한 십 리 가까운 길을 가야 한다.', '소녀가 걸음을 멈추며,', '\"너, 저 산 너머에 가 본 일 있니?\"', '벌 끝을 가리켰다.', '\"없다.\"', '\"우리, 가 보지 않으련?', '시골 오니까 혼자서 심심해 못 견디겠다.\"', '\"저래 봬도 멀다.\"', '\"멀면 얼마나 멀기에?', '서울 있을 땐 사뭇 먼 데까지 소풍 갔었다.\"', \"소녀의 눈이 금새 '바보,바보,'할 것만 같았다.\", '논 사잇길로 들어섰다.', '벼 가을걷이하는 곁을 지났다.', '허수아비가 서 있었다.', '소년이 새끼줄을 흔들었다.', '참새가 몇 마리 날아간다.', \"'참, 오늘은 일찍 집으로 돌아가 텃논의 참새를 봐야 할걸.'\", '하는 생각이 든다.', '\"야, 재밌다!\"', '소녀가 허수아비 줄을 잡더니 흔들어 댄다.', '허수아비가 자꾸 우쭐거리며 춤을 춘다.', '소녀의 왼쪽 볼에 살포시 보조개가 패었다.', '저만큼 허수아비가 또 서 있다.', '소녀가 그리로 달려간다.', '그 뒤를 소년도 달렸다.', '오늘 같은 날은 일찍 집으로 돌아가 집안일을 도와야 한다는 생각을 잊어버리기라도 하려는 듯이.', '소녀의 곁을 스쳐 그냥 달린다.', '메뚜기가 따끔따끔 얼굴에 와 부딪친다.', '쪽빛으로 한껏 갠 가을 하늘이 소년의 눈앞에서 맴을 돈다.', '어지럽다.', '저놈의 독수리, 저놈의 독수리, 저놈의 독수리가 맴을 돌고 있기 때문이다.', '돌아다보니, 소녀는 지금 자기가 지나쳐 온 허수아비를 흔들고 있다.', '좀 전 허수아비보다 더 우쭐거린다.', '논이 끝난 곳에 도랑이 하나 있었다.', '소녀가 먼저 뛰어 건넜다.', '거기서부터 산 밑까지는 밭이었다.', '수숫단을 세워 놓은 밭머리를 지났다.', '\"저게 뭐니?\"', '\"원두막.\"', '\"여기 참외, 맛있니?\"', '\"그럼, 참외 맛도 좋지만 수박 맛은 더 좋다.\"', '\"하나 먹어 봤으면.\"', '소년이 참외 그루에 심은 무우밭으로 들어가, 무우 두 밑을 뽑아 왔다.', '아직 밑이 덜 들어 있었다.', '잎을 비틀어 팽개친 후, 소녀에게 한개 건넨다.', '그리고는 이렇게 먹어야 한다는 듯이, 먼저 대강이를 한 입 베물어 낸 다음, 손톱으로 한 돌이 껍질을 벗겨 우쩍 깨문다.', '소녀도 따라 했다.', '그러나, 세 입도 못 먹고,', '\"아, 맵고 지려.\"', '하며 집어던지고 만다.', '\"참, 맛 없어 못 먹겠다.\"', '소년이 더 멀리 팽개쳐 버렸다.', '산이 가까워졌다.', '단풍이 눈에 따가웠다.', '\"야아!\"', '소녀가 산을 향해 달려갔다.', '이번은 소년이 뒤따라 달리지 않았다.', '그러고도 곧 소녀보다 더 많은 꽃을 꺾었다.', '\"이게 들국화, 이게 싸리꽃, 이게 도라지꽃,…….\"', '\"도라지꽃이 이렇게 예쁜 줄은 몰랐네.', '난 보랏빛이 좋아!…… 그런데, 이 양산 같이 생긴 노란 꽃이 뭐지?\"', '\"마타리꽃.\"', '소녀는 마타리꽃을 양산 받듯이 해 보인다.', '약간 상기된 얼굴에 살포시 보조개를 떠올리며.', '다시 소년은 꽃 한 옴큼을 꺾어 왔다.', '싱싱한 꽃가지만 골라 소녀에게 건넨다.', '그러나 소녀는', '\"하나도 버리지 마라.\"', '산마루께로 올라갔다.', '맞은편 골짜기에 오순도순 초가집이 몇 모여 있었다.', '누가 말할 것도 아닌데, 바위에 나란히 걸터앉았다.', '유달리 주위가 조용해진 것 같았다.', '따가운 가을 햇살만이 말라가는 풀 냄새를 퍼뜨리고 있었다.', '\"저건 또 무슨 꽃이지?\"', '적잖이 비탈진 곳에 칡덩굴이 엉키어 꽃을 달고 있었다.', '\"꼭 등꽃 같네.', '서울 우리 학교에 큰 등나무가 있었단다.', '저 꽃을 보니까 등나무 밑에서 놀던 동무들 생각이 난다.\"', '소녀가 조용히 일어나 비탈진 곳으로 간다.', '꽃송이가 많이 달린 줄기를 잡고 끊기 시작한다.', '좀처럼 끊어지지 않는다.', '안간힘을 쓰다가 그만 미끄러지고 만다.', '칡덩굴을 그러쥐었다.', '소년이 놀라 달려갔다.', '소녀가 손을 내밀었다.', '손을 잡아 이끌어 올리며, 소년은 제가 꺾어다 줄 것을 잘못했다고 뉘우친다.', '소녀의 오른쪽 무릎에 핏방울이 내맺혔다.', '소년은 저도 모르게 생채기에 입술을 가져다 대고 빨기 시작했다.', '그러다가, 무슨 생각을 했는지 홱 일어나 저 쪽으로 달려간다.', '좀 만에 숨이 차 돌아온 소년은', '\"이걸 바르면 낫는다.\"', '송진을 생채기에다 문질러 바르고는 그 달음으로 칡덩굴 있는 데로 내려가, 꽃 많이 달린 몇 줄기를 이빨로 끊어 가지고 올라온다.', '그리고는,', '\"저기 송아지가 있다.', '그리 가 보자.\"', '누렁송아지였다.', '아직 코뚜레도 꿰지 않았다.', '소년이 고삐를 바투 잡아 쥐고 등을 긁어 주는 체 훌쩍 올라탔다.', '송아지가 껑충거리며 돌아간다.', '소녀의 흰 얼굴이, 분홍 스웨터가, 남색 스커트가, 안고 있는 꽃과 함께 범벅이 된다.', '모두가 하나의 큰 꽃묶음 같다.', '어지럽다.', '그러나, 내리지 않으리라.', '자랑스러웠다.', '이것만은 소녀가 흉내 내지 못할, 자기 혼자만이 할 수 있는 일인 것이다.', '\"너희, 예서 뭣들 하느냐?\"', '농부(農夫)하나가 억새풀 사이로 올라왔다.', '송아지 등에서 뛰어내렸다.', '어린 송아지를 타서 허리가 상하면 어쩌느냐고 꾸지람을 들을 것만 같다.', '그런데, 나룻이 긴 농부는 소녀 편을 한 번 훑어보고는 그저 송아지 고삐를 풀어 내면서,', '\"어서들 집으로 가거라.', '소나기가 올라.\"', '참, 먹장구름 한 장이 머리 위에 와 있다.', '갑자기 사면이 소란스러워진 것 같다.', '바람이 우수수 소리를 내며 지나간다.', '삽시간에 주위가 보랏빛으로 변했다.', '산을 내려오는데, 떡갈나무 잎에서 빗방울 듣는 소리가 난다.', '굵은 빗방울이었다.', '목덜미가 선뜻선뜻했다.', '그러자, 대번에 눈앞을 가로막는 빗줄기.', '비안개 속에 원두막이 보였다.', '그리로 가 비를 그을 수밖에.', '그러나, 원두막은 기둥이 기울고 지붕도 갈래갈래 찢어져 있었다.', '그런 대로 비가 덜 새는 곳을 가려 소녀를 들어서게 했다.', '소녀의 입술이 파아랗게 질렸다.', '어깨를 자꾸 떨었다.', '무명 겹저고리를 벗어 소녀의 어깨를 싸 주었다.', '소녀는 비에 젖은 눈을 들어 한 번 쳐다보았을 뿐, 소년이 하는 대로 잠자코 있었다.', '그리고는, 안고 온 꽃묶음 속에서 가지가 꺾이고 꽃이 일그러진 송이를 골라 발 밑에 버린다.', '소녀가 들어선 곳도 비가 새기 시작했다.', '더 거기서 비를 그을 수 없었다.', '밖을 내다보던 소년이 무엇을 생각했는지 수수밭 쪽으로 달려간다.', '세워 놓은 수숫단 속을 비집어 보더니, 옆의 수숫단을 날라다 덧세운다.', '다시 속을 비집어 본다.', '그리고는 이쪽을 향해 손짓을 한다.', '수숫단 속은 비는 안 새었다.', '그저 어둡고 좁은 게 안 됐다.', '앞에 나앉은 소년은 그냥 비를 맞아야만 했다.', '그런 소년의 어깨에서 김이 올랐다.', '소녀가 속삭이듯이, 이리 들어와 앉으라고 했다.', '괜찮다고 했다.', '소녀가 다시, 들어와 앉으라고 했다.', '할 수 없이 뒷걸음질을 쳤다.', '그 바람에, 소녀가 안고 있는 꽃묶음이 망그러졌다.', '그러나, 소녀는 상관없다고 생각했다.', '비에 젖은 소년의 몸 내음새가 확 코에 끼얹혀졌다.', '그러나, 고개를 돌리지 않았다.', '도리어 소년의 몸기운으로 해서 떨리던 몸이 적이 누그러지는 느낌이었다.', '소란하던 수숫잎 소리가 뚝 그쳤다.', '밖이 멀개졌다.', '수숫단 속을 벗어 나왔다.', '멀지 않은 앞쪽에 햇빛이 눈부시게 내리붓고 있었다.', '도랑 있는 곳까지 와 보니, 엄청나게 물이 불어 있었다.', '빛마저 제법 붉은 흙탕물이었다.', '뛰어 건널 수가 없었다.', '소년이 등을 돌려 댔다.', '소녀가 순순히 업히었다.', '걷어올린 소년의 잠방이까지 물이 올라왔다.', \"소녀는 '어머나'소리를 지르며 소년의 목을 끌어안았다.\", '개울가에 다다르기 전에, 가을 하늘이 언제 그랬는가 싶게 구름 한 점 없이 쪽빛으로 개어 있었다.', '그 뒤로 소녀의 모습은 뵈지 않았다.', '매일같이 개울가로 달려와 봐도 뵈지 않았다.', '학교에서 쉬는 시간에 운동장을 살피기도 했다.', '남 몰래 5학년 여자 반을 엿보기도 했다.', '그러나, 뵈지 않았다.', '그날도 소년은 주머니 속 흰 조약돌만 만지작거리며 개울가로 나왔다.', '그랬더니, 이 쪽 개울둑에 소녀가 앉아 있는 게 아닌가.', '소년은 가슴부터 두근거렸다.', '\"그 동안 앓았다.\"', '어쩐지 소녀의 얼굴이 해쓱해져 있었다.', '\"그 날, 소나기 맞은 탓 아냐?\"', '소녀가 가만히 고개를 끄덕이었다.', '\"인제 다 났냐?\"', '\"아직도…….\"', '\"그럼, 누워 있어야지.\"', '\"하도 갑갑해서 나왔다.', '……참, 그 날 재밌었어…….', '그런데그 날 어디서 이런 물이 들었는지 잘 지지 않는다.\"', '소녀가 분홍 스웨터 앞자락을 내려다본다.', '거기에 검붉은 진흙물 같은 게 들어 있었다.', '소녀가 가만히 보조개를 떠올리며,', '\"그래 이게 무슨 물 같니?\"', '소년은 스웨터 앞자락만 바라보고 있었다.', '\"내, 생각해 냈다.', '그 날, 도랑을 건너면서 내가 업힌 일이 있지?', '그 때, 네 등에서 옮은 물이다.\"', '소년은 얼굴이 확 달아오름을 느꼈다.', '갈림길에서 소녀는', '\"저, 오늘 아침에 우리 집에서 대추를 땄다.', '낼 제사 지내려고…….\"', '대추 한 줌을 내준다.', '소년은 주춤한다.', '\"맛봐라.', '우리 증조(曾祖)할아버지가 심었다는데, 아주 달다.\"', '소년은 두 손을 오그려 내밀며,', '\"참, 알도 굵다!\"', '\"그리고 저, 우리 이번에 제사 지내고 나서 좀 있다.', '집을 내주게 됐다.\"', '소년은 소녀네가 이사해 오기 전에 벌써 어른들의 이야기를 들어서, 윤 초시 손자(孫子)가 서울서 사업에 실패해 가지고 고향에 돌아오지 않을 수 없게 되었다는 걸 알고 있었다.', '그것이 이번에는 고향 집마저 남의 손에 넘기게 된 모양이었다.', '\"왜 그런지 난 이사 가는 게 싫어졌다.', '어른들이 하는 일이니 어쩔 수 없지만…….\"', '전에 없이, 소녀의 까만 눈에 쓸쓸한 빛이 떠돌았다.', '소녀와 헤어져 돌아오는 길에, 소년은 혼잣속으로, 소녀가 이사를 간다는 말을 수없이 되뇌어 보았다.', '무어 그리 안타까울 것도 서러울 것도 없었다.', '그렇건만, 소년은 지금 자기가 씹고 있는 대추알의 단맛을 모르고 있었다.', '이 날 밤, 소년은 몰래 덕쇠 할아버지네 호두밭으로 갔다.', '낯에 봐 두었던 나무로 올라갔다.', '그리고, 봐 두었던 가지를 향해 작대기를 내리쳤다.', '호두송이 떨어지는 소리가 별나게 크게 들렸다.', '가슴이 선뜩했다.', '그러나 다음 순간, 굵은 호두야 많이 떨어져라, 많이 떨어져라, 저도 모를 힘에 이끌려 마구 작대기를 내리 치는 것이었다.', '돌아오는 길에는 열 이틀 달이 지우는 그늘만 골라 디뎠다.', '그늘의 고마움을 처음 느꼈다.', '불룩한 주머니를 어루만졌다.', '호두송이를 맨손으로 깠다가는 옴이 오르기 쉽다는 말 같은 건 아무렇지도 않았다.', '그저 근동에서 제일 가는 이 덕쇠 할아버지네 호두를 어서 소녀에게 맛보여야 한다는 생각만이 앞섰다.', '그러다, 아차 하는 생각이 들었다.', '소녀더러 병이 좀 낫거들랑 이사 가기 전에 한 번 개울가로 나와 달라는 말을 못해 둔 것이었다.', '바보 같은것, 바보 같은것.', '이튿날, 소년이 학교에서 돌아오니, 아버지가 나들이옷으로 갈아입고 닭 한 마리를 안고 있었다.', '어디 가시느냐고 물었다.', '그 말에도 대꾸도 없이, 아버지는 안고 있는 닭의 무게를 겨냥해 보면서,', '\"이만하면 될까?\"', '어머니가 망태기를 내주며,', '\"벌써 며칠째 \\'걀걀\\'하고 알 날 자리를 보던데요.', '크진 않아도살은 쪘을 거여요.\"', '소년이 이번에는 어머니한테 아버지가 어디 가시느냐고 물어 보았다.', '\"저, 서당골 윤 초시 댁에 가신다.', '제삿상에라도 놓으시라고…….\"', '\"그럼, 큰 놈으로 하나 가져가지.', '저 얼룩수탉으로…….\"', '이 말에, 아버지는 허허 웃고 나서,', '\"임마, 그래도 이게 실속이 있다.\"', '소년은 공연히 열적어, 책보를 집어던지고는 외양간으로가, 쇠잔등을 한 번 철썩 갈겼다.', '쇠파리라도 잡는 체.', '개울물은 날로 여물어 갔다.', '소년은 갈림길에서 아래쪽으로 가 보았다.', '갈밭머리에서 바라보는 서당골 마을은 쪽빛 하늘 아래 한결 가까워 보였다.', '어른들의 말이, 내일 소녀네가 양평읍으로 이사 간다는 것이었다.', '거기 가서는 조그마한 가겟방을 보게 되리라는 것이었다.', '소년은 저도 모르게 주머니 속 호두알을 만지작거리며, 한 손으로는 수없이 갈꽃을 휘어 꺾고 있었다.', '그 날 밤, 소년은 자리에 누워서도 같은 생각뿐이었다.', '내일 소녀네가 이사하는 걸 가 보나 어쩌나.', '가면 소녀를 보게 될까 어떨까.', '그러다가 까무룩 잠이 들었는가 하는데,', '\"허, 참 세상일도…….\"', '마을 갔던 아버지가 언제 돌아왔는지,', '\"윤 초시 댁도 말이 아니야, 그 많던 전답을 다 팔아 버리고, 대대로 살아오던 집마저 남의 손에 넘기더니, 또 악상까지 당하는걸 보면…….\"', '남폿불 밑에서 바느질감을 안고 있던 어머니가,', '\"증손(曾孫)이라곤 계집애 그 애 하나뿐이었지요?\"', '\"그렇지, 사내 애 둘 있던 건 어려서 잃어버리고…….\"', '\"어쩌면 그렇게 자식복이 없을까.\"', '\"글쎄 말이지.', '이번 앤 꽤 여러 날 앓는 걸 약도 변변히 못써 봤다더군.', '지금 같아서 윤 초시네도 대가 끊긴 셈이지.……그런데참, 이번 계집앤 어린 것이 여간 잔망스럽지가 않아.', '글쎄, 죽기전에 이런 말을 했다지 않아?', '자기가 죽거든 자기 입던 옷을 꼭그대로 입혀서 묻어 달라고…….\"']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kcpOrgRCO-IN",
    "outputId": "06e9c7ee-ba6c-4e8f-9eee-e64d8ee409f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['이', '문장', '이', '형태소', '단위', '로', '잘', '출력', '되', '나요', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.morphs(\"이 문장이 형태소 단위로 잘 출력되나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "AVmrImWNLu6K"
   },
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "# 5. <<Exercise 1>> 주어진 sentences를 이용하여, sentences를 각 문장별로 형태소 분석한 morph_sentences를 implementation 해주세요.\n",
    "\n",
    "# sentences: ['소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수 있었다.',\n",
    "#             '소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다.',\n",
    "#             ... ]\n",
    "#########################################################################################################################\n",
    "\n",
    "\n",
    "morph_sentences = []\n",
    "for sentence in sentences:\n",
    "    temp = \"\"\n",
    "    morphs = tokenizer.morphs(sentence)\n",
    "    for morph in morphs:\n",
    "      temp = temp + \" \" + morph\n",
    "\n",
    "    morph_sentences.append(temp.strip())\n",
    "\n",
    "\n",
    "# <expected results>\n",
    "# morph_sentences: ['소년 은 개울가 에서 소녀 를 보 자 곧 윤 초시 네 증손녀 ( 曾孫女 ) 딸 이 라는 것 을 알 ㄹ 수 있 었 다 .',\n",
    "#                   '소녀 는 개울 에다 손 을 잠그 고 물장난 을 하 고 있 는 것 이 다 .',\n",
    "#                   ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EZOns9Immuw",
    "outputId": "c0bb5032-5590-4c8d-92fd-f7ff83e33826"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수 있었다.\n",
      "소년 은 개울가 에서 소녀 를 보 자 곧 윤 초시 네 증손녀 ( 曾孫女 ) 딸 이 라는 것 을 알 ㄹ 수 있 었 다 .\n",
      "\n",
      "소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다.\n",
      "소녀 는 개울 에다 손 을 잠그 고 물장난 을 하 고 있 는 것 이 다 .\n"
     ]
    }
   ],
   "source": [
    "# 6. 형태소 분석된 결과물 확인\n",
    "\n",
    "print(sentences[0])\n",
    "print(morph_sentences[0])\n",
    "print()\n",
    "print(sentences[1])\n",
    "print(morph_sentences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KysxZCltLwC_"
   },
   "outputs": [],
   "source": [
    "# 7. 형태소 분석된 각 sentence들을 한 줄에 한 문장씩 sonagi.txt 파일로 작성\n",
    "\n",
    "with open('sonagi.txt', 'wt', encoding='utf-8') as f:\n",
    "    for line in morph_sentences:\n",
    "        f.write(line.strip())\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "19N303W_LxBJ",
    "outputId": "1f824560-484b-48bd-d766-dfaa5fa4beaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'쳐다보', '머리', '소년', '아', '일어', '씹', '\"', '유달리', '만지작거리', '바르', '한', '죽', '무슨', '를', '올르', '기울', '애', '한껏', '입', '가운데', '소녀', '돌아오', '데', '스치', '생채기', '얼굴', '옆', '오르', '수탉', '춤', '밭머리', '사뭇', '사내', '큰길', '저기', '시작', '가을걷이', '그러하', '곧', '잠자코', '째', '분홍', '줄', '공연히', '우리', '사이', '겠', '갈', '실패', '나풀거리', '주위', '제가', '제법', '벌', '입도', '잠방이', '주춤', '잘', '찌', '집', '자', '일어서', '자고', '그대로', '입히', '이것', '들국화', '다는', '증손', '말하', ')', '고마움', '라', '비탈지', '걸음', '도리어', '꺾이', '빛', '다시', '등나무', '조심', '범벅', '코피', '내려다보', '갈림길', '아래쪽', '열적', '복', '소리', '볼', '비치', '마리', '윤', '껑충거리', '이끌리', '내', '뵈', '날쌔', '밖', '가로막', '눕', '수박', '양산', '어지럽', '하', '딸', '그래', '달', '동무', '끼얹히', '변변히', '단맛', '내다보', '가져가', '야', '놓', '꽤', '질리', '손톱', '곳', '노랗', '어야지', '약도', '망그러지', '악상', '두', '여도', '새끼', '갈아입', '한결', '돌이', '잘못하', '나룻', '들길', '사잇길', '싱싱', '재미있', '순순히', '!', '쓰', '임', '패', '억새풀', '한테', '앞서', '순간', '걸어가', '진흙물', '제삿상', '잔등', '나', '학교', '소풍', '메밀밭', '지나', '날로', '고개', '건만', '서럽', '긋', '꽃가지', '흙탕물', '가깝', '집어던지', '찢어지', '마라', '비단', '겹', '손짓', '새끼줄', '듯이', '손자', '쉬', '디딤돌', '미끄러지', '뒤', '에서', '봐', '닭', '코', '曾祖', '마구', '증손녀', '물', '속', '증조', '되뇌', '달리기', '따르', '돕', '되', '수숫단', '아버지', '싸리', '끌어안', '눈', '끝나', 'ㄹ걸', '적이', '별나', '되리', '움키', '굵', '으라', '들리', '이만', '던데요', '좋', '옷', '점', '누렁', '조약돌', '며', '좁', '허수아비', '나타나', '물장난', '먹', '기둥', '등', '우쭐거리', '건느', '냐', '디', '대번에', '빠지', '처음', '허허', '개', '적잖이', '뒤따라오', '시작하', '에다', '한참', '먼저', '주머니', '유난히', '몸', '자기', '꺾', '내밀', '스', '떡갈나무', '지붕', '내지', '여자', '예쁘', '해쓱', '그리하', '와', '돌아서', '너머', '코뚜레', '학년', '세상일', '과', '마냥', '이르', '에게', '엉키', '려고', '농부', '맞은편', 'ㄴ다고', '오', '얼마나', '놀', '을까', '살포시', '김', '어루만지', '가지', '바투', '상관없', '갈기', '징검다리', '새', '들여다보', '는', '확', '군', '뭣', '어야', '빛나', '더러', '돌', '그리로', '청량', '없', '듯', '전답', '양', '개울물', '조그마', '에', '스럽', '바람', '심', '?', '어깨', '팽개치', '꼭', '함께', 'ㄹ까', '말라가', '수', '생기', '얼룩', '버릇', '으련', '선뜻', '서', '지나가', '모이', '받', '재밌', '조개', '책보', '햇빛', '둘', '업히', '가시', '무어', '마', '전', '혼자', '그만', '도', '견디', '대', '생각', '훔쳐내', '아야', '따끔따끔', '맛있', '붇', '떠돌', '떨어지', '없이', '꽃', '나란히', '상기', '잣', '병이', '못하', '좀더', '호두', '약간', '왜', '그렇', '고는', '스커트', '앓', '자식', '세수', '이리', '발', '양평읍', '빗방울', 'ㄴ데', '고기', '모양', '이제', '마을', '아찔', '셈', '어서', '열', '건너오', '대꾸', '안타깝', '자꾸', '텃논의', '허리', '먹장', '면서', '날아오', '손', '나오', '목', '개울', '멀리', '내맺히', '기', '로', '두근거리', '얼르', '철썩', '같이', '그런', '날아가', '조', '도라지', '무게', '내주', '아래', '막', '돌아다보', '망태기', '느냐', '들', '단풍', '찌르', '세', '송', '느끼', '農夫', '아침', '려는', '조용히', '……', '멀', '아니', '참외', '남폿불', '저만큼', '많', '메밀꽃', '힘', '않', '선뜩', '늦', '저래', '만이', '고르', '내일', '번', '단다', '닿', '리', '께', '당하', '오른쪽', '내리붓', '쇠', '벌써', '어제', '그냥', '그러', '가리', '니', 'ㄴ다', '훌쩍', '이튿날', '잠그', '곱', '심심', '오그리', '난', '그리', '일찍', '느낌', '산', '문득', '냄새', '겨냥', '曾孫', '내가', '홱', '구석', '까', '어쩐지', '떨구', '아차', '운동장', '빤히', 'ㄴ다는', '(', '가', '리라', '바보', '더', '웃', '아서', '감', '대강이', '아도', '기슭', '그러쥐', '들어서', '뽑', '내려가', '려', '뭐', '자꾸만', '반짝거리', '앞', '송진', '엄청나', '낯', '다행', '바닥', '잊어버리', '뒤따르', '내리치', '탓', '너희', '젖', '알도', '수없이', '여', '같', '건네', '나들이', '끊', '이상', '흔들', '흉내', '달려오', '으리라', ',', '맴', '비추', '매일', '쯤', '있', '이리로', '댁', '자랑', '어머니', '많이', '쉽', '초시', '뚝', '쓸쓸', '헛디디', '원두막', '소매', '허탕', '어른', '둑', '움직이', '건너가', '따갑', '하나', '삼', '끊어지', '낫', '들어오', '휘', '붉', '안간힘', '내려오', '孫子', '지우', '나앉', '허', '때', '잡', '변하', '쥐', '깜짝', '벗', '모르', '따', '뉘우치', '거라', '떨', '고', '긁', '토요일', '아무렇', '엿보', '며칠', '우쩍', '의', '듣', '빨', '지내', '올라오', '처럼', '대추', '더니', '그리고', '검', '멀개지', '뛰', '등에', '어도', '미간', '혼', '쪽빛', '라도', '시간', '싶', '밑', '것', '파아랗', '눈부시', '비가', '속삭이', '이틀', '가기', '상당', '실수', '수수밭', 'ㄴ가', '그러나', '이야기', '내리', '훑어보', '맑', '건너', \"'\", '체하', '올라가', '삽시간', '때문', '갈래갈래', '기운', '거', '가겟방', '괜찮', '문지르', '지만', '그늘', '네', '어', '어쩌', '이번', '어디', '밭', '해지', '비', '인제', '다', '살피', '을', 'ㄴ', '물기', '검붉', '고향', '지르', '앞쪽', '빗줄기', '덧세우', '더니만', 'ㄹ', '남', '줄기', '서당골', '몰래', '알', '맵', '제사', '천천', '숨', '지', '풀', '희', '오랜', '돌리', '사람', '여태', '올라타', '낳', '우수수', '살아오', '뒷걸음', '보', '달라', '참', '달아오르', '었', '였', '바느질', '그날', '팔짝팔짝', '어떻', '다지', '이런', '으로', '기에', '거들랑', '는지', '쇠파리', '았', '으시', '라는', '제일', '떠올리', '걀걀', '개울가', '고삐', '헤어지', '갈꽃', '살', '말', '걸터앉', '오늘', '모습', '등꽃', '꾸지람', '지금', '맞', '들이', '부터', '다고', '걷어올리', '줌', '넣', '曾孫女', '사면', '메뚜기', '앉', '동안', '올라서', '그저', '수숫잎', '가면', '부딪치', '논', '은', '거든', '면', '얘', '요', '골짜기', '타', '대로', '놈', '길', '그', '베물', '그것', '거기', '질', '그림자', '반', '잃어버리', '끝', '모두', '할아버지', '체', '벌떡', '돌아가', '눈앞', '무릎', '근동', '구나', '에는', '밖에', '갑갑', '비키', '쪽', '벼', '요행', '이빨', '치', '덕', '떨리', '그럼', '무명', '작대기', '뿐', '찝찔', '날', '흘러들', '깨물', '비안개', '그치', '그런데', '꽃묶음', '는가', '일그러지', '비집', '어둡', '넘기', '하면', '물이', '단발', '마저', '송이', '까맣', '앤', '어떤', '남색', '핏방울', '얼마', '까지', '가만히', '옮', '라고', '니까', '끄덕이', '소란', '들어가', '으면', '옴큼', '마장', '계집애', '지요', '햇살', '보다', '저놈', '저', '발돋움', '추', '이쪽', '맨손', '대대로', '싫', '이렇', '뛰어내리', '걷히', '계속', '여간', '조용', '못', '다음', 'ㄹ라', '위', '외양간', '누', '건', '싸', '자리', '그루', '번번이', '초가집', '달이', '5', '하늘', '편', '꽃송이', '송아지', '덜', '퍼뜨리', '가슴', '몇', '갑자기', '이끌', '이름', '팔', '여물', '무우', '장', '일어나', '올리', '입술', '독수리', '이', '마주치', '건너편', '곁', '비틀', '잠', '마타리', '여기', '허전', '잎', '주', '수록', '주무르', '갈밭', '어리', '바위', '누그러지', '사업', '까무룩', '오순도순', '차', '저고리', '글쎄', '벗기', '구름', '버리', '는데', '짜릿', '상하', '가을', '음', '실속', '여러', '다가', '향하', '앞자락', '잔망', '아직', '나무', '지나치', '하얗', '아주', '또', '개지', '밤', '십', '게', '예서', '도랑', '우대', '골', '묻', '머', '달려가', '다다르', '보조개', '디디', '액체', '목덜미', '좀처럼', '저쯤', '도랑이', '불룩', '보이', '기다리', '멈추', '껍질', '언제', '후', '보랏빛', '일', '맛', '크', 'ㄴ지', '내음', '칡덩굴', '시골', '서울', '가리키', '집안일을', '세우', '끊기', '안', '스웨터', '소나기', '.', 'ㅁ', '이사', '금새', '무엇', '바라보', '느', '참새', '좀', '산마루', '꿰', '만', '계집', '왼쪽', '달리'}\n"
     ]
    }
   ],
   "source": [
    "# 8. 형태소 분석된 각 sentence의 형태소들을 전부 set에 집어넣어 중복을 삭제, set에 들어있는 vocab을 한 줄에 한 형태소씩 .voc 파일로 작성\n",
    "\n",
    "vocab = set()\n",
    "for sentence in morph_sentences:\n",
    "    temp = sentence.split()\n",
    "    for t in temp:\n",
    "        vocab.add(t)\n",
    "\n",
    "print(vocab)\n",
    "\n",
    "with open('sonagi.voc', 'wt', encoding='utf-8') as f:\n",
    "    for line in vocab:\n",
    "        f.write(line.strip())\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "au2RwXvElH4T",
    "outputId": "87113120-ce8e-4a2d-b2a4-fa55e2bd6754"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buckwheat_flowers.arpa\tbuckwheat_flowers.txt  sample_data  sonagi.doc\n",
      "buckwheat_flowers.bin\tbuckwheat_flowers.voc  sonagi.arpa  sonagi.txt\n",
      "buckwheat_flowers.doc\tkenlm\t\t       sonagi.bin   sonagi.voc\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h63hHQfLy6xp"
   },
   "source": [
    "## Step 2: Language model 생성\n",
    "\n",
    "\n",
    "### &emsp;>> ! kenlm/build/bin/lmplz -o [N] < [txt file] > [model file]\n",
    "&emsp;&emsp;[N] : 사용할 모델의 n-gram\n",
    "\n",
    "</br> &emsp;&emsp;[txt file] : 학습(counting)에 사용할 문서 경로\n",
    "\n",
    "</br> &emsp;&emsp;[model file] : 생성할 모델 파일명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d3g_yzHeLzbs",
    "outputId": "adf62792-dedc-485c-8740-03e0aff6cbaa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/sonagi.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2514862080 bytes == 0x558f08f4c000 @  0x7f97f2c021e7 0x558f0779a7a2 0x558f0773551e 0x558f077142eb 0x558f07700066 0x7f97f0d9bbf7 0x558f07701baa\n",
      "tcmalloc: large alloc 8382865408 bytes == 0x558f9eda8000 @  0x7f97f2c021e7 0x558f0779a7a2 0x558f077897ca 0x558f0778a208 0x558f07714308 0x558f07700066 0x7f97f0d9bbf7 0x558f07701baa\n",
      "****************************************************************************************************\n",
      "Unigram tokens 4557 types 944\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:11328 2:3799259392 3:7123611648\n",
      "tcmalloc: large alloc 7123615744 bytes == 0x558f08f4c000 @  0x7f97f2c021e7 0x558f0779a7a2 0x558f077897ca 0x558f0778a208 0x558f077148d7 0x558f07700066 0x7f97f0d9bbf7 0x558f07701baa\n",
      "tcmalloc: large alloc 3799261184 bytes == 0x5591930da000 @  0x7f97f2c021e7 0x558f0779a7a2 0x558f077897ca 0x558f0778a208 0x558f07714cdd 0x558f07700066 0x7f97f0d9bbf7 0x558f07701baa\n",
      "Statistics:\n",
      "1 944 D1=0.611292 D2=1.3648 D3+=1.54079\n",
      "2 2776 D1=0.81196 D2=1.32834 D3+=1.96069\n",
      "3 3499 D1=0.881735 D2=1.49321 D3+=1.53761\n",
      "Memory estimate for binary LM:\n",
      "type     kB\n",
      "probing 150 assuming -p 1.5\n",
      "probing 170 assuming -r models -p 1.5\n",
      "trie     68 without quantization\n",
      "trie     45 assuming -q 8 -b 8 quantization \n",
      "trie     66 assuming -a 22 array pointer compression\n",
      "trie     44 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:11328 2:44416 3:69980\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:11328 2:44416 3:69980\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:14638784 kB\tVmRSS:2478060 kB\tRSSMax:2497916 kB\tuser:0.18332\tsys:1.08564\tCPU:1.269\treal:1.28987\n"
     ]
    }
   ],
   "source": [
    "# 9. kenlm 모델 build\n",
    "\n",
    "! kenlm/build/bin/lmplz -o 3 <sonagi.txt> sonagi.arpa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C77ePn8uRcp2",
    "outputId": "81a2b7d7-6a52-4bd9-b219-ed528caf6e6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "buckwheat_flowers.arpa\tbuckwheat_flowers.txt  sample_data  sonagi.doc\n",
      "buckwheat_flowers.bin\tbuckwheat_flowers.voc  sonagi.arpa  sonagi.txt\n",
      "buckwheat_flowers.doc\tkenlm\t\t       sonagi.bin   sonagi.voc\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3cozxk_yzJI2"
   },
   "source": [
    "## Step 3: Binary file로 Model 변환\n",
    "### &emsp;>> ! kenlm/build/bin/build_binary [model file] [bin model file]\n",
    "\n",
    "&emsp;&emsp;[N] : n-gram\n",
    "\n",
    "</br>&emsp;&emsp;[model file] : 이미 생성된 모델 파일명\n",
    "\n",
    "</br>&emsp;&emsp;[bin model file] : binary로 생성할 모델 파일명"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VLk8DGA5L1dQ",
    "outputId": "9a6f3f1c-12fd-416f-e89b-52a050d42ecd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading sonagi.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "# 10. 생성된 kenlm 모델 파일 binary  file로 변환\n",
    "\n",
    "! kenlm/build/bin/build_binary sonagi.arpa sonagi.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxDftsRfL1_d",
    "outputId": "9fd309eb-7f2c-4140-adfa-7b01634811b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This binary file contains probing hash tables.\n",
      "소녀=7 2 -1.0026854\t가=72 3 -0.31729177\t소년=3 1 -2.551379\t을=23 1 -2.055063\t</s>=2 1 -2.7724392\tTotal: -8.698858 OOV: 0\n",
      "Perplexity including OOVs:\t54.92520066053768\n",
      "Perplexity excluding OOVs:\t54.92520066053768\n",
      "OOVs:\t0\n",
      "Tokens:\t5\n",
      "Name:query\tVmPeak:42352 kB\tVmRSS:6036 kB\tRSSMax:6036 kB\tuser:0.003256\tsys:0\tCPU:0.00329119\treal:0.000538565\n",
      "Loading the LM will be faster if you build a binary file.\n",
      "Reading sonagi.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "소녀=7 2 -1.0026854\t가=72 3 -0.31729177\t소년=3 1 -2.551379\t을=23 1 -2.055063\t</s>=2 1 -2.7724392\tTotal: -8.698858 OOV: 0\n",
      "Perplexity including OOVs:\t54.92520066053768\n",
      "Perplexity excluding OOVs:\t54.92520066053768\n",
      "OOVs:\t0\n",
      "Tokens:\t5\n",
      "Name:query\tVmPeak:42200 kB\tVmRSS:6136 kB\tRSSMax:6136 kB\tuser:0.002729\tsys:0.002729\tCPU:0.00550429\treal:0.00285034\n"
     ]
    }
   ],
   "source": [
    "# 11. model 이 제대로 생성 되었는지 확인\n",
    "# ! echo \"원하는 문장\" | kenlm/build/bin/query [(bin) model file]\n",
    "\n",
    "! echo \"소녀 가 소년 을\" | kenlm/build/bin/query sonagi.bin\n",
    "! echo \"소녀 가 소년 을\" | kenlm/build/bin/query sonagi.arpa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUsVg6IhzToE"
   },
   "source": [
    "## Step 4: model을 활용하여 주어진 시퀀스 scoring\n",
    "\n",
    "### &emsp;>> model.score('여름 이 었 다 . ', bos=True, eos=True)\n",
    "### &emsp;>> model.score('여름 이 었 ', bos=True, eos=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aohuLOD2L3E-"
   },
   "outputs": [],
   "source": [
    "# 12. 생성한 모델 불러오기\n",
    "import kenlm\n",
    "\n",
    "model_file = 'sonagi.bin' \n",
    "# model_file = 'sonagi.arpa' # arpa 모델도 사용가능하나, binary 파일이 속도가 좀더 빠름.\n",
    "\n",
    "model = kenlm.Model(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pK9QiuqUL4Ao",
    "outputId": "ef133fee-a50e-4c3a-fbd3-34548eb0e600"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> 여름 이 었 다 . </s> : -6.305783748626709\n",
      "<s> 여름 이 었 : -6.258444786071777\n"
     ]
    }
   ],
   "source": [
    "# 13. 시퀀스 scoring 예시\n",
    "\n",
    "# model.score('주어진 시퀀스', bos=True, eos=True)\n",
    "# bos : 모델이 scoring하도록 주어진 시퀀스 내에서 sentence가 시작했는가\n",
    "# eos : 모델이 scoring하도록 주어진 시퀀스 내에서 sentence가 종결되었는가\n",
    "\n",
    "# 이미 완성한 시퀀스(문장)의 scoring을 위해서는 bos=True eos=True\n",
    "# bos=True로 하면 모델이 시퀀스의 앞에 <s>를 추가하고,\n",
    "# eos=True인 경우 모델이 시퀀스의 뒤에 </s>를 추가하여 score를 계산함\n",
    "\n",
    "#따라서 bos=True, eos=True는 '<s> 원하는 시퀀스 </s>' 의 scoring을 한 것임.\n",
    "\n",
    "\n",
    "#  \"<s> 여름 이 었 다 . </s>\" 를 scoring'\n",
    "eos_score = model.score('여름 이 었 다 .', bos=True, eos=True)\n",
    "print(\"<s> 여름 이 었 다 . </s> :\", eos_score)\n",
    "\n",
    "#  \"<s> 여름 이 었\" 을 scoring\n",
    "no_eos_score = model.score('여름 이 었', bos=True, eos=False)\n",
    "print(\"<s> 여름 이 었 :\", no_eos_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7EcGs1h3xXv"
   },
   "source": [
    "## Step 5: 주어진 시퀀스에서 다음 형태소 예측\n",
    "\n",
    "### &emsp;<< Exercise 2>> '소년 은 소녀 를' 다음에 올 가장 자연스러운 형태소를 찾아주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "URqEQ5LkL55H"
   },
   "outputs": [],
   "source": [
    "# 14. vocab list 파일 불러오기\n",
    "\n",
    "vocab_file = 'sonagi.voc'\n",
    "vocab_list = []\n",
    "with open(vocab_file, 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        vocab_list.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZpoQfp8L6oS",
    "outputId": "500f1b30-3d19-4ed7-e446-8cdb20860d41"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best vocab:  보\n"
     ]
    }
   ],
   "source": [
    "###########################################################################################################################\n",
    "# 15. << Exercise 2 >> 주어진 시퀀스('소년 은 소녀 를') 다음의 형태소를 예측 : 주어진 시퀀스에 voc list의 형태소 하나를 합쳐서 score를 계산\n",
    "\n",
    "# 주어진 시퀀스에 preprocessing하며 만든 sonagi.voc 파일의 형태소를 하나씩 붙여서 가장 score가 높은 형태소를 찾음\n",
    "# voc = ['가', '만', '사업', ...] 이라면,\n",
    "#'소년 은 소녀 가' 의 점수, '소년 은 소녀 만', '소년 은 소녀 사업 ', ... 등의 score를 계산하고 그 중 가장 높은 score를 지닌 형태소를 찾음\n",
    "############################################################################################################################\n",
    "\n",
    "best_vocab = None\n",
    "best_score = None\n",
    "\n",
    "for vocab in vocab_list:\n",
    "    sequence_cand = \"소년 은 소녀 를 \" + vocab\n",
    "    score_cand = model.score(sequence_cand, bos=True, eos=False)\n",
    "\n",
    "    if best_vocab is None:\n",
    "      best_score = score_cand\n",
    "      best_vocab = vocab\n",
    "\n",
    "    if best_score < score_cand:\n",
    "      best_score = score_cand\n",
    "      best_vocab = vocab\n",
    "\n",
    "sequence_cand = \"소년 은 소녀 를\"\n",
    "score_cand = model.score(sequence_cand, bos=True, eos=True)\n",
    "\n",
    "if best_score < score_cand:\n",
    "  best_score = score_cand\n",
    "  best_vocab = '</s>'\n",
    "\n",
    "print(\"Best vocab: \", best_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdmfWMpe4MhX"
   },
   "source": [
    "## Step 6: 주어진 시퀀스로 시작하는 가장 자연스러운 문장 예측\n",
    "\n",
    "#### </br>&emsp;<< Exercise 3 >> Step 5와 loop문을 사용하여,\n",
    "#### </br> &emsp;'소년 은 소녀 를' 으로 시작하는 가장 자연스러운 문장을 찾아주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Iyc4XiqUL8cA"
   },
   "outputs": [],
   "source": [
    "###############################################################################################################################\n",
    "# 16. << Exercise 3 >> 15를 auto-regressive하게 loop 문으로 반복하여 주어진 시퀀스 '소년 은 소녀 를' 로 시작한 문장이 어떻게 끝날지 예측해주세요.\n",
    "\n",
    "# 1) 주어진 시퀀스에서 문장이 종결될 경우의 score를 계산\n",
    "# 2) 주어진 시퀀스에서 문장이 종결되지 않을 경우에 그 다음에 올 가장 자연스러운 형태소와 score를 계산\n",
    "# 3) 만약 1)보다 2)의 score가 더 높다면, 시퀀스에 2)에서 찾아낸 형태소를 추가하고, 다시 1)부터 반복\n",
    "# 4) 만약 1)의 score가 2)의 score 보다 더 높다면, 그대로 시퀀스를 마무리 함\n",
    "###############################################################################################################################\n",
    "\n",
    "def predict(model_path, voc_path):\n",
    "    # load language model with KenLM\n",
    "    model = kenlm.Model(model_path)\n",
    "    print(\"Language Model at \" + model_path + \" loaded.\")\n",
    "\n",
    "    # load vocabulary (or load word list)\n",
    "    voc = []\n",
    "    file_reader = open(voc_path, \"r\", encoding='utf-8')\n",
    "    for line in file_reader:\n",
    "        voc.append(line.strip())\n",
    "    print(\"Vocabulary at \" + voc_path + \" loaded\\n\")\n",
    "\n",
    "    sequence = input('Sequence: ')\n",
    "\n",
    "    print(\"Given sequence: \" + sequence)\n",
    "\n",
    "    # prediction loop\n",
    "    loop_condition = True\n",
    "    while loop_condition:\n",
    "        best_score = None \n",
    "        best_vocab = None \n",
    "\n",
    "        for vocab in voc:\n",
    "            sequence_cand = sequence + \" \" + vocab\n",
    "            sequence_score = model.score(sequence_cand, bos=True, eos=False)\n",
    "\n",
    "            if best_score is None:\n",
    "                best_score = sequence_score\n",
    "                best_vocab = vocab\n",
    "\n",
    "            if best_score < sequence_score:\n",
    "                best_score = sequence_score\n",
    "                best_vocab = vocab\n",
    "\n",
    "        eos_sentence = sequence\n",
    "        eos_score = model.score(eos_sentence, bos=True, eos=True)\n",
    "        \n",
    "        if eos_score < best_score:\n",
    "            sequence = sequence + \" \" + best_vocab\n",
    "      \n",
    "        else:\n",
    "            loop_condition = False\n",
    "\n",
    "\n",
    "    print(\"Result: \" + sequence)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p9M1VzEIL8fw",
    "outputId": "3177027b-1525-46cd-e8f2-6f93784a4eb1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model at sonagi.arpa loaded.\n",
      "Vocabulary at sonagi.voc loaded\n",
      "\n",
      "Sequence: 소년 은 소녀 를\n",
      "Given sequence: 소년 은 소녀 를\n",
      "Result: 소년 은 소녀 를 보 게 되 었 다 .\n"
     ]
    }
   ],
   "source": [
    "# 17. 16을 실행 \n",
    "\n",
    "model_path = 'sonagi.arpa'\n",
    "voc_path = 'sonagi.voc'\n",
    "predict(model_path, voc_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ELatjR6K4zzB"
   },
   "source": [
    "## Step 7: 다른 말뭉치로 학습한 모델과 비교\n",
    "\n",
    "#### </br> &emsp;<< Exercise 3 >> Step 1, 2, 3, 4, 6을 참고하여, \n",
    "#### </br> &emsp;bucketwheat_flowers.doc를 사용한 모델을 생성하여 \n",
    "#### </br> &emsp;주어진 시퀀스('소년 은 소녀 를', '개울가 가', '여름 에')로 시작하는 가장 자연스러운 문장들을 찾고, \n",
    "#### </br> &emsp;sonagi.doc를 사용한 경우와 비교해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bOBIYmOhL_dY",
    "outputId": "b8cb552c-02c1-4511-8a0c-a76a31cd2a09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 1/5 Counting and sorting n-grams ===\n",
      "Reading /content/buckwheat_flowers.txt\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "tcmalloc: large alloc 2514862080 bytes == 0x55abd2048000 @  0x7f266b9281e7 0x55abd120a7a2 0x55abd11a551e 0x55abd11842eb 0x55abd1170066 0x7f2669ac1bf7 0x55abd1171baa\n",
      "tcmalloc: large alloc 8382865408 bytes == 0x55ac67ea4000 @  0x7f266b9281e7 0x55abd120a7a2 0x55abd11f97ca 0x55abd11fa208 0x55abd1184308 0x55abd1170066 0x7f2669ac1bf7 0x55abd1171baa\n",
      "****************************************************************************************************\n",
      "Unigram tokens 4807 types 1193\n",
      "=== 2/5 Calculating and sorting adjusted counts ===\n",
      "Chain sizes: 1:14316 2:3799258368 3:7123609600\n",
      "tcmalloc: large alloc 7123615744 bytes == 0x55abd2048000 @  0x7f266b9281e7 0x55abd120a7a2 0x55abd11f97ca 0x55abd11fa208 0x55abd11848d7 0x55abd1170066 0x7f2669ac1bf7 0x55abd1171baa\n",
      "tcmalloc: large alloc 3799261184 bytes == 0x55ae5c1d6000 @  0x7f266b9281e7 0x55abd120a7a2 0x55abd11f97ca 0x55abd11fa208 0x55abd1184cdd 0x55abd1170066 0x7f2669ac1bf7 0x55abd1171baa\n",
      "Statistics:\n",
      "1 1193 D1=0.65812 D2=1.23987 D3+=1.73504\n",
      "2 3390 D1=0.850789 D2=1.24411 D3+=1.67409\n",
      "3 4153 D1=0.935009 D2=1.32434 D3+=1.63999\n",
      "Memory estimate for binary LM:\n",
      "type     kB\n",
      "probing 182 assuming -p 1.5\n",
      "probing 207 assuming -r models -p 1.5\n",
      "trie     85 without quantization\n",
      "trie     57 assuming -q 8 -b 8 quantization \n",
      "trie     82 assuming -a 22 array pointer compression\n",
      "trie     54 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
      "=== 3/5 Calculating and sorting initial probabilities ===\n",
      "Chain sizes: 1:14316 2:54240 3:83060\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
      "Chain sizes: 1:14316 2:54240 3:83060\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "####################################################################################################\n",
      "=== 5/5 Writing ARPA model ===\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "Name:lmplz\tVmPeak:14638780 kB\tVmRSS:2478208 kB\tRSSMax:2497920 kB\tuser:0.19252\tsys:1.04955\tCPU:1.2421\treal:1.2492\n",
      "Reading buckwheat_flowers.arpa\n",
      "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
      "****************************************************************************************************\n",
      "SUCCESS\n"
     ]
    }
   ],
   "source": [
    "####################################################################################################################\n",
    "# 18. << Exercise 4 >> : bucketwheat_flowers.doc를 사용한 모델을 생성하여 sonagi.doc를 사용한 경우와 주어진 시퀀스에 대한 output을 비교해주세요.\n",
    "# 주어진 시퀀스: '소년 은 소녀 를', '개울가 가', '여름 에'\n",
    "\n",
    "# sonata.doc를 data preprocessing하여 sonata.txt, sonata.voc를 생성.\n",
    "# sonata.txt, sonata.voc를 이용하여 모델을 생성, load하여서\n",
    "# 같은 문장에 대해서 sonagi corpus를 이용한 경우와 sonata corpus를 이용한 경우에 output이 어떠한지 출력\n",
    "####################################################################################################################\n",
    "\n",
    "# Data preprocessing. 형태소 분하여 buckwheat_flowers.txt, buckwheat_flowers.voc 작성\n",
    "b_lines = []\n",
    "with open('buckwheat_flowers.doc', 'rt', encoding='utf-8') as b_f:\n",
    "    for b_line in b_f:\n",
    "        b_lines.append(b_line)\n",
    "\n",
    "b_sentences = []\n",
    "for line in b_lines:\n",
    "    b_sentences.extend(sent_tokenize(line))\n",
    "\n",
    "b_morph_sentences = []\n",
    "for sentence in b_sentences:\n",
    "    temp = \"\"\n",
    "    for morpheme in tokenizer.morphs(sentence):\n",
    "      temp = temp + \" \" + morpheme\n",
    "    b_morph_sentences.append(temp.strip())\n",
    "\n",
    "with open('buckwheat_flowers.txt', 'wt', encoding='utf-8') as f:\n",
    "    for line in b_morph_sentences:\n",
    "        f.write(line.strip())\n",
    "        f.write('\\n')\n",
    "\n",
    "b_vocab = set()\n",
    "for sentence in b_morph_sentences:\n",
    "    temp = sentence.split()\n",
    "    for t in temp:\n",
    "        b_vocab.add(t)\n",
    "\n",
    "with open('buckwheat_flowers.voc', 'wt', encoding='utf-8') as f:\n",
    "    for line in b_vocab:\n",
    "        f.write(line.strip())\n",
    "        f.write('\\n')\n",
    "\n",
    "\n",
    "# n-gram language model을 buckwheat_flowers로 학습\n",
    "\n",
    "! kenlm/build/bin/lmplz -o 3 <buckwheat_flowers.txt> buckwheat_flowers.arpa\n",
    "! kenlm/build/bin/build_binary buckwheat_flowers.arpa buckwheat_flowers.bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IADqh60wtMp2",
    "outputId": "11cf0903-c47e-48c0-9452-c7140a6bd942"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Model at buckwheat_flowers.arpa loaded.\n",
      "Vocabulary at buckwheat_flowers.voc loaded\n",
      "\n",
      "Sequence: 개울가 가\n",
      "Given sequence: 개울가 가\n",
      "Result: 개울가 가 어디 없이 하얗 ㄴ 것 이 었 다 .\n"
     ]
    }
   ],
   "source": [
    "# 19. 18을 실행\n",
    "\n",
    "model_path2 = 'buckwheat_flowers.arpa'\n",
    "voc_path2 = 'buckwheat_flowers.voc'\n",
    "predict(model_path2, voc_path2)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practice_konlpy_kenlm.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
