{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MIWdWJ8v_Em"
   },
   "source": [
    "# NLP 실습 #3: N-gram Language model\n",
    "황순원의 '소나기' 로 trigram language model 학습하고 사용해보기\n",
    "</br>\n",
    "</br>\n",
    "\n",
    "* 준비 : konlpy와 nltk의 tokenizer 설명\n",
    "\n",
    "* Step 1: Data preprocessing - tokenization\n",
    "\n",
    "* Step 2: Probability Table을 생성\n",
    "\n",
    "* Step 3: Probability Table을 활용하여 시퀀스 확률 찾기\n",
    "\n",
    "* Step 4: 주어진 시퀀스에서 다음 형태소 예측\n",
    "\n",
    "* Step 5: 주어진 시퀀스로 시작하는 문장을 예측\n",
    "\n",
    "\n",
    "</br>\n",
    "</br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-3f24c6d75cc1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msent_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "from konlpy.tag import Kkma\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u58Vf5yByd-j"
   },
   "source": [
    "## 준비: konlpy의 형태소 분석기와 nltk의 tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8sMydXeJivy7",
    "outputId": "c60dda78-b1be-496f-c904-6af335c2f2d4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'konlpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-bc3a0091e7c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 2. konlpy의 Kkma 형태소 분석기 import, 형태소 분석 예제\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkonlpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKkma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'konlpy'"
     ]
    }
   ],
   "source": [
    "# 1. konlpy의 Kkma 형태소 분석기 import, 형태소 분석 예제\n",
    "\n",
    "tokenizer = Kkma()\n",
    "tokenizer.morphs(\"이 문장이 형태소 단위로 잘 출력되나요?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxOsfjyKLaJ2",
    "outputId": "33d278e2-68bc-478e-eff7-a40ed563d776"
   },
   "outputs": [],
   "source": [
    "# 이전에 nltk 및 'punkt' 모듈을 다운로드 하지 않은 경우에 주석을 풀고 run\n",
    "\n",
    "sent_tokenize('입력이 문장 단위로 잘 구분되는지 확인해보세요. sent_tokenize는 한 line을 받아서 마침표를 기준으로 여러 문장으로 분리해주는 함수입니다! 이 문장은 세번째 문장입니다. 이 문장은 네번째 문장입니다!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THyoh5vyyvTE"
   },
   "source": [
    "## Step 1: Data preprocessing - tokenization\n",
    "&emsp;&emsp; sonagi.doc의 내용을 문장 단위로 분리.\n",
    "\n",
    "</br> &emsp;&emsp; <<Exercise 1>> 각 문장을 kkma 분석기로 형태소 단위로 분리.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gkaozFjwLqAF"
   },
   "outputs": [],
   "source": [
    "# 4. nltk import하고 sonagi.doc을 읽어들임. nltk의 sent_tokenize를 이용하여 sonagi.doc의 내용을 문장 단위로 분리\n",
    "\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "lines = []\n",
    "with open('sonagi.doc', 'rt', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        lines.append(line)\n",
    "\n",
    "sentences = []\n",
    "for line in lines:\n",
    "    sentences.extend(sent_tokenize(line))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q6MrcQOMNTM-",
    "outputId": "66b41116-1c0e-4d1c-b997-0a4e0b3e5ebd"
   },
   "outputs": [],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AVmrImWNLu6K"
   },
   "outputs": [],
   "source": [
    "#########################################################################################################################\n",
    "# 5. <<Exercise 1>> 주어진 sentences를 이용하여, sentences를 각 문장별로 형태소 분석한 morph_sentences를 implementation 해주세요.\n",
    "\n",
    "# sentences: ['소년은 개울가에서 소녀를 보자 곧 윤 초시네 증손녀(曾孫女)딸이라는 걸 알 수 있었다.',\n",
    "#             '소녀는 개울에다 손을 잠그고 물장난을 하고 있는 것이다.',\n",
    "#             ... ]\n",
    "#########################################################################################################################\n",
    "\n",
    "\n",
    "morphs_lst = []\n",
    "for sentence in sentences:\n",
    "    temp = tokenizer.morphs(sentence)\n",
    "    morphs_lst.append(temp)\n",
    "\n",
    "\n",
    "# <expected results>\n",
    "# morphs_lst: [['소년', '은', '개울가', '에서', '소녀', '를', '보', '자', '곧', '윤', '초시', '네', '증손녀', '(', '曾孫女', ')', '딸', '이', '라는', '것', '을', '알', 'ㄹ', '수', '있', '었', '다', '.'],\n",
    "#         ['소녀', '는', '개울', '에다', '손', '을', '잠그', '고', '물장난', '을', '하', '고', '있', '는', '것', '이', '다', '.'],\n",
    "#                   ... ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_EZOns9Immuw",
    "outputId": "3104cac8-8819-4c0d-8980-3ad5c6abd554"
   },
   "outputs": [],
   "source": [
    "# 6. 형태소 분석된 결과물 확인\n",
    "\n",
    "print(sentences[0])\n",
    "print(morphs_lst[0])\n",
    "print()\n",
    "print(sentences[1])\n",
    "print(morphs_lst[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THyoh5vyyvTE"
   },
   "source": [
    "## Step 2 Probability Table을 생성\n",
    "&emsp;&emsp; << Exercise 1 >> 형태소 단위로 분리된 각 문장들의 trigram을 찾아서 리스트로 저장\n",
    "\n",
    "</br> &emsp;&emsp; << Exercise 2 >> 리스트로 저장된 trigram을 종류 별로 count하여 dictionary 형의 probability table을 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CxDftsRfL1_d",
    "outputId": "46ceb081-2f38-4904-8924-d3911bb630fd"
   },
   "outputs": [],
   "source": [
    "# << Exercise 1 >>\n",
    "# Goal: 형태소 단위로 분리된 각 문장들의 trigram을 찾아서 리스트로 저장.\n",
    "# \n",
    "# input: morphs- 한 문장의 형태소들의 list.\n",
    "#         ex) [pad, <s>, 소녀, 는, 개울, 에다, 손, 을, 잠그, 고, 물장난, 을, 하, 고, 있, 는, 것, 이, 다, . </s>, pad]\n",
    "# output: trigrams - 입력 문장의 모든 trigram을 tuple로 표현한 list.\n",
    "#         ex) [((pad, <s>), 소녀), ((<s>, 소녀), 는), ((소녀, 는), 개울), ((는, 개울), 에다), ((개울, 에다), 손) ... ... ((이, 다), .), ((다, .), </s>), ((., </s>), pad),\n",
    "\n",
    "def find_trigram(morphs):\n",
    "    \n",
    "    trigrams = [((t0, t1,), t2) for t0, t1, t2 in zip(morphs, morphs[1:], morphs[2:])]\n",
    "    \n",
    "    return trigrams\n",
    "\n",
    "\n",
    "print(find_trigram(morphs_lst[1]))\n",
    "print()\n",
    "print(find_trigram(['pad', '<s>']  + morphs_lst[1]+ ['</s>','pad']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# << Exercise 2 >>\n",
    "# Goal: 형태소 분석된 전체 문서의 trigram들을 count하여 parsing table을 dictionary 형으로 저장.\n",
    "#       위의 find_trigram 함수를 활용할 것.\n",
    "# input : morphs_lst\n",
    "#        [['소년', '은', '개울가', '에서', '소녀', '를', '보', '자', '곧', '윤', '초시', '네', '증손녀', '(', '曾孫女', ')', '딸', '이', '라는', '것', '을', '알', 'ㄹ', '수', '있', '었', '다', '.'],\n",
    "#         ['소녀', '는', '개울', '에다', '손', '을', '잠그', '고', '물장난', '을', '하', '고', '있', '는', '것', '이', '다', '.'],\n",
    "#                   ... ]\n",
    "# output : trigram_freq\n",
    "#        {(pad, <s>): {소년: 25, 소녀: 35, 서울: 3, 벌써: 1, ...},\n",
    "#         (<s>, 소년): {은: 18, 이: 7, ...},\n",
    "#           ...\n",
    "#         (소년, 은): {개울가: 1, 개울: 1, 저: 3, 이: 1, 조약돌: 1, 전: 1, ...}}\n",
    "\n",
    "def count_trigram(morphs_lst):\n",
    "    trigram_freq = defaultdict(lambda: defaultdict(int))\n",
    "    for morphs in morphs_lst:\n",
    "        trigram_in_a_sentence = find_trigram(['pad', '<s>']  + morphs + ['</s>','pad'])\n",
    "        for trigram in trigram_in_a_sentence:\n",
    "            trigram_freq[trigram[0]][trigram[1]] += 1\n",
    "    return trigram_freq\n",
    "\n",
    "trigram_freq = count_trigram(morphs_lst)\n",
    "print(trigram_freq[('소년', '은')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUsVg6IhzToE"
   },
   "source": [
    "## Step 3: model을 활용하여 주어진 시퀀스 확률 구하기\n",
    "&emsp;&emsp; << Exercise 2 >> 생성한 probability table을 사용하여 문장 '단풍 이 눈 에 따갑 없 다 .' 의 확률을 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# << Exercise 3 >>\n",
    "# Goal: '단풍 이 눈 에 따갑 었 다 .' 의 확률 구하기\n",
    "# input: target_trigram - [((pad, <s>), 단풍), ((<s>, 단풍), 이), ((단풍, 이), 눈), ((아, 눈), 에), ... (., </s>, pad)]\n",
    "# output: probability - 0.0013549039433771487\n",
    "\n",
    "target = \"pad <s> 단풍 이 눈 에 따갑 었 다 . </s> pad\".split()\n",
    "target_trigram = find_trigram(target)\n",
    "print(target_trigram)\n",
    "\n",
    "def find_score(target_trigram, trigram_freq):\n",
    "    prob = 1\n",
    "    for trigram in target_trigram:\n",
    "        numerator = 0\n",
    "        denominator = 0\n",
    "        for unigram, count in trigram_freq.get(trigram[0], {}).items():\n",
    "            if unigram == trigram[1]:\n",
    "                numerator = count\n",
    "            denominator += count\n",
    "            \n",
    "        if denominator == 0:\n",
    "            temp_prob = 0.\n",
    "        else:\n",
    "            temp_prob = numerator / denominator\n",
    "            \n",
    "        prob *= temp_prob\n",
    "    return prob\n",
    "\n",
    "find_score(target_trigram, trigram_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7EcGs1h3xXv"
   },
   "source": [
    "## Step 4: 주어진 시퀀스에서 다음 형태소 예측\n",
    "\n",
    "### &emsp;<< Exercise 2>> '어쩐지' 다음에 올 가장 자연스러운 형태소를 찾아주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# << Exercise 4 >> \n",
    "# Goal: \"어쩐지\" 다음에 올 형태소로 가장 적합한 것은?\n",
    "# input: target - [pad, <s>, 소녀, 가]\n",
    "#        trigram_freq - {(pad, <s>): {소년: 25, 소녀: 35, 서울: 3, 벌써: 1, ...},\n",
    "#                        (<s>, 소년): {은: 18, 이: 7, ...},\n",
    "#                            ...\n",
    "#                        (소년, 은): {개울가: 1, 개울: 1, 저: 3, 이: 1, 조약돌: 1, 전: 1, ...}}\n",
    "# output: best_token - '앉'\n",
    "\n",
    "target = \"pad <s> 어쩐지\".split()\n",
    "\n",
    "def find_next_token(target, trigram_freq):\n",
    "    highest_count = 0\n",
    "    best_token = None\n",
    "    for unigram, count in trigram_freq.get((target[-2], target[-1]), {}).items():\n",
    "        if highest_count < count:\n",
    "            highest_count = count\n",
    "            best_token = unigram\n",
    "\n",
    "    return best_token\n",
    "print(find_next_token(target, trigram_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tdmfWMpe4MhX"
   },
   "source": [
    "## Step 5: 주어진 시퀀스로 시작하는 가장 자연스러운 문장 예측\n",
    "\n",
    "#### </br>&emsp;<< Exercise 3 >> Step 4와 loop문을 사용하여,\n",
    "#### </br> &emsp;'어쩐지' 으로 시작하는 가장 자연스러운 문장을 찾아주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# << Exercise 5 >>\n",
    "# Goal: \"어쩐지\"로 시작하는 가장 자연스러운 문장을 찾아주세요.\n",
    "# input: target - [pad, <s>, 소녀, 가]\n",
    "#        trigram_freq - {(pad, <s>): {소년: 25, 소녀: 35, 서울: 3, 벌써: 1, ...},\n",
    "#                        (<s>, 소년): {은: 18, 이: 7, ...},\n",
    "#                            ...\n",
    "#                        (소년, 은): {개울가: 1, 개울: 1, 저: 3, 이: 1, 조약돌: 1, 전: 1, ...}}\n",
    "# output: full_sentence - [어쩐지, 소녀, 의, 그림자, 가, 뵈, 지, 않, 았, 다, ., </s>]\n",
    "\n",
    "def fine_full_sentence(partial_sentence, trigram_freq)\n",
    "    loop_condition = True\n",
    "    full_sentence= partial_sentence\n",
    "\n",
    "    while (loop_condition):\n",
    "        next_token = find_next_token(partial_sentence.split(), trigram_freq)\n",
    "        partial_sentence += \" \" + next_token\n",
    "        if partial_sentence.split()[-1] == '</s>':\n",
    "            loop_condition = False\n",
    "            \n",
    "    return full_sentence\n",
    "print(fine_full_sentence(target, trigram_freq))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "practice_konlpy_kenlm.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
